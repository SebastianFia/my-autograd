# my-autograd

My Python implementation of the *Autograd* algorithm, which sits at the core of libraries such as *PyTorch* and *Tensorflow*.
This is an unoptimized and simplified version that works only for scalar values, not for tensors.
In the nn.py we implement a MLP, and in optim.py we implement a SGD optimizer. An example training on a toy dataset can be seen in example.py.

